{
  "_args": [
    [
      "word-frequency-analyzer@0.0.1",
      "/home/funkyfisch/Desktop/Hackathon2017"
    ]
  ],
  "_from": "word-frequency-analyzer@0.0.1",
  "_id": "word-frequency-analyzer@0.0.1",
  "_inCache": true,
  "_installable": true,
  "_location": "/word-frequency-analyzer",
  "_npmUser": {
    "email": "aslong87@gmail.com",
    "name": "aslong87"
  },
  "_npmVersion": "1.2.14",
  "_phantomChildren": {},
  "_requested": {
    "name": "word-frequency-analyzer",
    "raw": "word-frequency-analyzer@0.0.1",
    "rawSpec": "0.0.1",
    "scope": null,
    "spec": "0.0.1",
    "type": "version"
  },
  "_requiredBy": [
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/word-frequency-analyzer/-/word-frequency-analyzer-0.0.1.tgz",
  "_shasum": "1da9b0ad362cfa8f3640b704dc4dbc1fab3ef5a7",
  "_shrinkwrap": null,
  "_spec": "word-frequency-analyzer@0.0.1",
  "_where": "/home/funkyfisch/Desktop/Hackathon2017",
  "author": {
    "email": "aslong87@gmail.com",
    "name": "Andrew Long"
  },
  "bugs": {
    "url": "https://github.com/aslong/word-frequency-analyzer/issues"
  },
  "dependencies": {
    "async": "0.2.5",
    "binary-search-tree": "0.2.3",
    "coffee-script": "1.6.3",
    "debug": "0.7.2",
    "underscore": "1.5.2"
  },
  "description": "Given a document as a string, return a list of the most frequently used words sorted by frequency.",
  "devDependencies": {
    "codo": "1.9.0",
    "grunt": "0.4.1",
    "grunt-cli": "0.1.9",
    "grunt-contrib-clean": "0.5.0",
    "grunt-contrib-coffee": "0.7.0",
    "grunt-contrib-connect": "0.5.0",
    "grunt-contrib-watch": "0.5.3",
    "grunt-contrib-yuidoc": "0.5.0",
    "grunt-exec": "0.4.2",
    "grunt-mocha-cli": "1.3.0",
    "mocha": "1.13.0",
    "should": "2.0.2",
    "yuidocjs": "0.3.46"
  },
  "directories": {
    "doc": "./docs"
  },
  "dist": {
    "shasum": "1da9b0ad362cfa8f3640b704dc4dbc1fab3ef5a7",
    "tarball": "https://registry.npmjs.org/word-frequency-analyzer/-/word-frequency-analyzer-0.0.1.tgz"
  },
  "engines": {
    "node": ">=0.10.0"
  },
  "homepage": "https://github.com/aslong/word-frequency-analyzer#readme",
  "main": "./bin/src/index.js",
  "maintainers": [
    {
      "name": "aslong87",
      "email": "aslong87@gmail.com"
    }
  ],
  "name": "word-frequency-analyzer",
  "optionalDependencies": {},
  "readme": "[![Build Status](https://travis-ci.org/aslong/word-frequency-analyzer.png?branch=master)](https://travis-ci.org/aslong/word-frequency-analyzer)\n[![Node Dependencies](https://david-dm.org/aslong/word-frequency-analyzer.png)](https://david-dm.org/aslong/word-frequency-analyzer.png)\n[![Node devDependency Status](https://david-dm.org/aslong/word-frequency-analyzer/dev-status.png)](https://david-dm.org/aslong/word-frequency-analyzer#info=devDependencies)\n\n# Word Frequency Analyzer\n  \nThe word frequency analyzer takes a string of text, parses it into words, and returns a list of words sorted by their frequency in the text. It can support multiple languages, and has several options that can be toggled for determining word matches. Currently the parser only supports english. Additional character sets can be added to enable other languages. \n\nYou can alter how words are determined to be the same or significant by the parser. Currently there is support for these modes:\n\n* Case sensitivity\n* Filter stop words\n* Use root of the word\n\nMultiple modes can be enabled at the same time. This allows for several different possible analyzers depending on your specific needs.\n\n**There are several ways to interface with the analyzer:**  \n\n- Include the npm lib in your project\n- HTTP API (uses [cluster api](http://nodejs.org/api/cluster.html) to make n workers for n cores)\n\n### Programming Interface\n\nDocumentation can be viewed [here](http://coffeedoc.info/github/aslong/word-frequency-analyzer/master/).\n\nCan also be built locally using [these steps](https://github.com/aslong/word-frequency-analyzer#building-documentation). The docs define the classes and modules available in the project.\n\n### Tools Used\nThe analyzer was written using [Coffeescript](http://coffeescript.org/) and [Node.js](http://nodejs.org/). [Grunt](http://gruntjs.com/) is used for the management of compilation, starting/restarting of services, running of test suites using [Mocha](http://visionmedia.github.io/mocha/) and [Should.js](https://github.com/visionmedia/should.js/), and documentation building. [Codo](https://github.com/netzpirat/codo) is the underlying generator used for documentation.\n\nProvisioning for the service is done using [Chef](http://www.opscode.com/chef/). [Vagrant](http://www.vagrantup.com/) is used with [Chef](http://www.opscode.com/chef/) for creating an isolated and replicable working environment. [Berkshelf](http://berkshelf.com/) is used for iterating on the chef cookbook and can\nbe re-enabled in the [Vagrantfile](https://github.com/aslong/word-frequency-analyzer/blob/master/Vagrantfile) if needed.\n\n[Travis CI](https://travis-ci.org/) is used for continuous integration. It's currently configured for running test suites on new git commits. [David-dm](https://david-dm.org/) is used for version tracking of latest npm modules used in the project. This includes both dev dependencies, and core dependencies.\n\n## Installation\n\nThe word frequency analyzer uses [Vagrant](http://www.vagrantup.com/) for building an isolated environment with everything necessary for usage or development.\nVagrant uses [VirtualBox](https://www.virtualbox.org/) to create VMs programmatically.\n\n1. [Install](https://www.virtualbox.org/wiki/Downloads) VirtualBox for your OS.\n1. [Install](http://downloads.vagrantup.com/) Vagrant for your OS.\n\n```\n$ git clone git@github.com:aslong/word-frequency-analyzer.git\n$ cd word-frequency-analyzer\n$ vagrant up\n```\nAt this point you may want to grab a coffee. First run of ```vagrant up``` will need to download a base vm image, and provision the vm with our software dependencies.\n\n## Usage\n\nAfter installation is complete, ssh into our created vm and cd to the directory for the analyzer.\n\n```\n$ vagrant ssh\n$ cd word_frequency_analyzer\n```\n\n### Running Tests\n\n```grunt``` is the primary command to use when running the various test suites. The suites are made up of unit and performance tests.\nYou can run any suite in isolation or all together. There is also a watch mode that can be used to re-run the tests on file updates.\n\n**All Test Suites:**  \n\n```\n$ grunt test\n```\n\n**All Test Suites (re-run on file updates):**  \n\n```\n$ grunt watch:tdd\n```\n\n**Unit Test Suite:**  \n\n```\n$ grunt test:unit\n```\n\n**Unit Test Suite (re-run on file updates):**  \n\n```\n$ grunt watch:unit\n```\n\n**Perf Test Suite:**  \n\n```\n$ grunt test:perf\n```\n\n**Perf Test Suite (re-run on file updates):**  \n\n```\n$ grunt watch:perf\n```\n\n### Running Service\n\n**Starting:**  \n\n```\n$ grunt start\n```\nCompiles the source, and starts the node.js service.\n\n**Restarting:**  \n\n```\n$ grunt restart\n```\nCleans the bin directory, compiles the source, and starts the node.js service.\n\n### Building Documentation\n\n**Generate documentation and start doc server:**  \n\n```\n$ grunt docs\n```\nAfter running, visit [here](http://localhost:9000) to view the documentation.  \n\n**Watch and generate new docs on change:**  \n\n```\n$ grunt watch:docs\n```\nAnytime a source file is updated the docs for it will be regenerated. You should only have to refresh your browser to see the updates, assuming you have ```grunt docs``` also running.\n\n\n## Cleaning up VM resources\n\n**Pause the VM**\n\n```\n$ vagrant suspend\n```\n\n**Shutdown the VM**\n\n```\n$ vagrant halt\n```\n\n**Shutdown and Delete the VM image**\n\n```\n$ vagrant destroy\n```\n\n\n## Contributing\n\nIf there are any changes or improvements you want to this project, [create an issue](https://github.com/aslong/word-frequency-analyzer/issues) or fork the project and submit a [pull request](https://github.com/aslong/word-frequency-analyzer/pulls) with the intended change. Please include a description of the feature. Pull requests should have accompanying tests. Thank you for your help with improving this tool for others. \n\n\n## License\n(The MIT License)\n\nCopyright (c) 2013 Andrew Long <aslong87@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/aslong/word-frequency-analyzer.git"
  },
  "scripts": {
    "prepublish": "grunt prepublish",
    "test": "grunt test"
  },
  "version": "0.0.1"
}
